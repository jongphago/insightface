{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpt.data import join_face_df\n",
    "from fpt.path import DTFR\n",
    "DATA_CATEGORY = \"aihub_family\"\n",
    "face_df = join_face_df(DTFR, DATA_CATEGORY)\n",
    "face_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/jupyter/data/face-image/train_aihub_family/\"\n",
    "count = 0\n",
    "dir_paths = []\n",
    "for dir_path, dir_names, file_names in os.walk(root):\n",
    "    if not file_names:\n",
    "        continue\n",
    "    for file in file_names:\n",
    "        dir_paths.append(dir_path)\n",
    "        if not file.endswith(\"jpg\"):\n",
    "            print(file)\n",
    "            continue\n",
    "        else:\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(dir_paths)), count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recognition.arcface_torch.aihub_train_v2 import main\n",
    "from recognition.arcface_torch.partial_fc_v2 import DistCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.aihub_r50_onegpu import config as aihub_config\n",
    "from configs.base import config as cfg\n",
    "\n",
    "cfg.update(aihub_config)\n",
    "cfg.output = \"work_dirs/aihub_r50_onegpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_distributed_sampler import setup_seed\n",
    "\n",
    "# global control random seed\n",
    "setup_seed(seed=cfg.seed, cuda_deterministic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 0\n",
    "local_rank = 0\n",
    "world_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import distributed\n",
    "\n",
    "\n",
    "# try:\n",
    "#     rank = int(os.environ[\"RANK\"])\n",
    "#     local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "#     world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "#     distributed.init_process_group(\"nccl\")\n",
    "# except KeyError:\n",
    "#     rank = 0\n",
    "#     local_rank = 0\n",
    "#     world_size = 1\n",
    "#     distributed.init_process_group(\n",
    "#         backend=\"nccl\",\n",
    "#         init_method=\"tcp://127.0.0.1:12584\",\n",
    "#         rank=rank,\n",
    "#         world_size=world_size,\n",
    "#     )\n",
    "\n",
    "# torch.cuda.set_device(local_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(cfg.output, exist_ok=True)\n",
    "# init_logging(rank, cfg.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "summary_writer = (\n",
    "    SummaryWriter(log_dir=os.path.join(cfg.output, \"tensorboard\"))\n",
    "    if rank == 0\n",
    "    else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# wandb_logger = None\n",
    "# if cfg.using_wandb:\n",
    "#     import wandb\n",
    "\n",
    "#     # Sign in to wandb\n",
    "#     try:\n",
    "#         wandb.login(key=cfg.wandb_key)\n",
    "#     except Exception as e:\n",
    "#         print(\"WandB Key must be provided in config file (base.py).\")\n",
    "#         print(f\"Config Error: {e}\")\n",
    "#     # Initialize wandb\n",
    "#     run_name = datetime.now().strftime(\"%y%m%d_%H%M\") + f\"_GPU{rank}\"\n",
    "#     run_name = (\n",
    "#         run_name\n",
    "#         if cfg.suffix_run_name is None\n",
    "#         else run_name + f\"_{cfg.suffix_run_name}\"\n",
    "#     )\n",
    "#     try:\n",
    "#         wandb_logger = (\n",
    "#             wandb.init(\n",
    "#                 entity=cfg.wandb_entity,\n",
    "#                 project=cfg.wandb_project,\n",
    "#                 sync_tensorboard=True,\n",
    "#                 resume=cfg.wandb_resume,\n",
    "#                 name=run_name,\n",
    "#                 # notes=cfg.notes,\n",
    "#             )\n",
    "#             if rank == 0 or cfg.wandb_log_all\n",
    "#             else None\n",
    "#         )\n",
    "#         if wandb_logger:\n",
    "#             wandb_logger.config.update(cfg)\n",
    "#     except Exception as e:\n",
    "#         print(\n",
    "#             \"WandB Data (Entity and Project name) must be provided in config file (base.py).\"\n",
    "#         )\n",
    "#         print(f\"Config Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_dataloader\n",
    "\n",
    "\n",
    "train_loader = get_dataloader(\n",
    "    cfg.rec, local_rank, cfg.batch_size, cfg.dali, cfg.seed, cfg.num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backbones import get_model\n",
    "\n",
    "backbone = get_model(\n",
    "    cfg.network, dropout=0.0, fp16=cfg.fp16, num_features=cfg.embedding_size\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.pretrained:\n",
    "    model_weights = torch.load(\n",
    "        f\"/home/jupyter/face/utils/model/arcface/{cfg.network}/backbone.pth\"\n",
    "    )\n",
    "    backbone.load_state_dict(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone = torch.nn.parallel.DistributedDataParallel(\n",
    "#     module=backbone,\n",
    "#     broadcast_buffers=False,\n",
    "#     device_ids=[local_rank],\n",
    "#     bucket_cap_mb=16,\n",
    "#     find_unused_parameters=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FIXME using gradient checkpoint if there are some unused parameters will cause error\n",
    "# backbone._set_static_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses import CombinedMarginLoss\n",
    "\n",
    "margin_loss = CombinedMarginLoss(\n",
    "    64,\n",
    "    cfg.margin_list[0],\n",
    "    cfg.margin_list[1],\n",
    "    cfg.margin_list[2],\n",
    "    cfg.interclass_filtering_threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from partial_fc_v2 import PartialFC_V2\n",
    "\n",
    "if cfg.optimizer == \"sgd\":\n",
    "    module_partial_fc = PartialFC_V2(\n",
    "        margin_loss, cfg.embedding_size, cfg.num_classes, cfg.sample_rate, cfg.fp16\n",
    "    )\n",
    "    module_partial_fc.train().cuda()\n",
    "    # TODO the params of partial fc must be last in the params list\n",
    "    opt = torch.optim.SGD(\n",
    "        params=[\n",
    "            {\"params\": backbone.parameters()},\n",
    "            {\"params\": module_partial_fc.parameters()},\n",
    "        ],\n",
    "        lr=cfg.lr,\n",
    "        momentum=0.9,\n",
    "        weight_decay=cfg.weight_decay,\n",
    "    )\n",
    "\n",
    "elif cfg.optimizer == \"adamw\":\n",
    "    module_partial_fc = PartialFC_V2(\n",
    "        margin_loss, cfg.embedding_size, cfg.num_classes, cfg.sample_rate, cfg.fp16\n",
    "    )\n",
    "    module_partial_fc.train().cuda()\n",
    "    opt = torch.optim.AdamW(\n",
    "        params=[\n",
    "            {\"params\": backbone.parameters()},\n",
    "            {\"params\": module_partial_fc.parameters()},\n",
    "        ],\n",
    "        lr=cfg.lr,\n",
    "        weight_decay=cfg.weight_decay,\n",
    "    )\n",
    "else:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lr_scheduler import PolyScheduler\n",
    "\n",
    "cfg.total_batch_size = cfg.batch_size * world_size\n",
    "cfg.warmup_step = cfg.num_image // cfg.total_batch_size * cfg.warmup_epoch\n",
    "cfg.total_step = cfg.num_image // cfg.total_batch_size * cfg.num_epoch\n",
    "\n",
    "lr_scheduler = PolyScheduler(\n",
    "    optimizer=opt,\n",
    "    base_lr=cfg.lr,\n",
    "    max_steps=cfg.total_step,\n",
    "    warmup_steps=cfg.warmup_step,\n",
    "    last_epoch=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if cfg.resume:\n",
    "#     dict_checkpoint = torch.load(os.path.join(cfg.output, f\"checkpoint_gpu_{rank}.pt\"))\n",
    "#     start_epoch = dict_checkpoint[\"epoch\"]\n",
    "#     global_step = dict_checkpoint[\"global_step\"]\n",
    "#     backbone.module.load_state_dict(dict_checkpoint[\"state_dict_backbone\"])\n",
    "#     module_partial_fc.load_state_dict(dict_checkpoint[\"state_dict_softmax_fc\"])\n",
    "#     opt.load_state_dict(dict_checkpoint[\"state_optimizer\"])\n",
    "#     lr_scheduler.load_state_dict(dict_checkpoint[\"state_lr_scheduler\"])\n",
    "#     del dict_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, value in cfg.items():\n",
    "#     num_space = 25 - len(key)\n",
    "#     logging.info(\": \" + key + \" \" * num_space + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.utils_callbacks import CallBackVerification\n",
    "\n",
    "# callback_verification = CallBackVerification(\n",
    "#     val_targets=cfg.val_targets,\n",
    "#     rec_prefix=cfg.rec,\n",
    "#     summary_writer=summary_writer,\n",
    "#     wandb_logger=wandb_logger,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils_callbacks import CallBackLogging\n",
    "\n",
    "callback_logging = CallBackLogging(\n",
    "    frequent=cfg.frequent,\n",
    "    total_step=cfg.total_step,\n",
    "    batch_size=cfg.batch_size,\n",
    "    start_step=global_step,\n",
    "    writer=summary_writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from utils.utils_logging import AverageMeter\n",
    "from torch.utils.data import DataLoader\n",
    "from facenet.validate_aihub import validate_aihub\n",
    "from aihub_dataloader import aihub_dataloader\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = datetime.today().strftime(\"%y%m%d-%H%M%S\")\n",
    "loss_am = AverageMeter()\n",
    "amp = torch.cuda.amp.grad_scaler.GradScaler(growth_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, cfg.num_epoch):\n",
    "    if isinstance(train_loader, DataLoader):\n",
    "        train_loader.sampler.set_epoch(epoch)\n",
    "        \n",
    "    for _, (img, local_labels) in enumerate(train_loader):\n",
    "        global_step += 1\n",
    "        local_embeddings = backbone(img)\n",
    "        loss: torch.Tensor = module_partial_fc(local_embeddings, local_labels)\n",
    "\n",
    "        if cfg.fp16:\n",
    "            amp.scale(loss).backward()\n",
    "            if global_step % cfg.gradient_acc == 0:\n",
    "                amp.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(backbone.parameters(), 5)\n",
    "                amp.step(opt)\n",
    "                amp.update()\n",
    "                opt.zero_grad()\n",
    "                lr_scheduler.step()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            if global_step % cfg.gradient_acc == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(backbone.parameters(), 5)\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "                lr_scheduler.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if wandb_logger:\n",
    "                wandb_logger.log(\n",
    "                    {\n",
    "                        \"Loss/Step Loss\": loss.item(),\n",
    "                        \"Loss/Train Loss\": loss_am.avg,\n",
    "                        \"Process/Step\": global_step,\n",
    "                        \"Process/Epoch\": epoch,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            loss_am.update(loss.item(), 1)\n",
    "            callback_logging(\n",
    "                global_step,\n",
    "                loss_am,\n",
    "                epoch,\n",
    "                cfg.fp16,\n",
    "                lr_scheduler.get_last_lr()[0],\n",
    "                amp,\n",
    "            )\n",
    "\n",
    "            if global_step % cfg.verbose == 0 and global_step > 0:\n",
    "                # callback_verification(global_step, backbone)\n",
    "                validate_aihub(backbone, aihub_dataloader, cfg.network, 0)\n",
    "\n",
    "    if cfg.save_all_states:\n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"global_step\": global_step,\n",
    "            \"state_dict_backbone\": backbone.module.state_dict(),\n",
    "            \"state_dict_softmax_fc\": module_partial_fc.state_dict(),\n",
    "            \"state_optimizer\": opt.state_dict(),\n",
    "            \"state_lr_scheduler\": lr_scheduler.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, os.path.join(cfg.output, f\"checkpoint_gpu_{rank}.pt\"))\n",
    "\n",
    "    if rank == 0:\n",
    "        path_module = os.path.join(cfg.output, \"model.pt\")\n",
    "        torch.save(backbone.module.state_dict(), path_module)\n",
    "\n",
    "        if wandb_logger and cfg.save_artifacts:\n",
    "            artifact_name = f\"{run_name}_E{epoch}\"\n",
    "            model = wandb.Artifact(artifact_name, type=\"model\")\n",
    "            model.add_file(path_module)\n",
    "            wandb_logger.log_artifact(model)\n",
    "\n",
    "    if cfg.dali:\n",
    "        train_loader.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank == 0:\n",
    "    path_module = os.path.join(cfg.output, \"model.pt\")\n",
    "    torch.save(backbone.module.state_dict(), path_module)\n",
    "\n",
    "    if wandb_logger and cfg.save_artifacts:\n",
    "        artifact_name = f\"{run_name}_Final\"\n",
    "        model = wandb.Artifact(artifact_name, type=\"model\")\n",
    "        model.add_file(path_module)\n",
    "        wandb_logger.log_artifact(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import normalize, linear\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import NLLLoss  # Negative Log Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(train_iter)\n",
    "images, local_labels = sample\n",
    "local_embeddings = backbone(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_checkpoint = torch.load(os.path.join(cfg.output, f\"checkpoint_gpu_{rank}.pt\"))\n",
    "weight = dict_checkpoint['state_dict_softmax_fc']['weight']\n",
    "# weight = torch.nn.Parameter(torch.normal(0, 0.01, (num_classes, embedding_size))).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = local_embeddings.size(0)\n",
    "num_classes = 2154\n",
    "embedding_size = 512\n",
    "world_size = 1\n",
    "rank = 0\n",
    "local_rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_cross_entropy = DistCrossEntropy()\n",
    "criterion = NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = local_labels.view(-1, 1)\n",
    "norm_embeddings = normalize(local_embeddings)\n",
    "norm_weight_activated = normalize(weight)\n",
    "logits = linear(norm_embeddings, norm_weight_activated)\n",
    "logits = logits.clamp(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = margin_loss(logits, labels)\n",
    "loss1 = dist_cross_entropy(logits, labels)\n",
    "loss2 = criterion(logits, labels.flatten())\n",
    "loss = loss1 + loss2\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
